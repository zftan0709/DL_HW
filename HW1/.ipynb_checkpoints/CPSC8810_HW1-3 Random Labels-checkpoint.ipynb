{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ** CPSC 8810 Deep Learning - HW1-3 **\n",
    "---\n",
    "\n",
    "## Introduction\n",
    "_**Note:** This assignment makes use of the MNIST dataset_\n",
    "\n",
    "The main objective of this assignments:\n",
    "* Fit network with random labels\n",
    "* Compare number of parameters vs generalization\n",
    "* Compare flatness vs generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "tf.__version__\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Dataset Preparation and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-2cdd42740c4c>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/zhifant/.conda/envs/DL_HW1/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/zhifant/.conda/envs/DL_HW1/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/MNIST/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/zhifant/.conda/envs/DL_HW1/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/MNIST/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/zhifant/.conda/envs/DL_HW1/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting data/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/zhifant/.conda/envs/DL_HW1/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "Training Dataset Size: 55000\n",
      "Validation Dataset Size: 5000\n",
      "Testing Dataset Size: 10000\n"
     ]
    }
   ],
   "source": [
    "data = input_data.read_data_sets('data/MNIST/', one_hot=True);\n",
    "\n",
    "train_num = data.train.num_examples\n",
    "valid_num = data.validation.num_examples\n",
    "test_num = data.test.num_examples\n",
    "img_flatten = 784\n",
    "img_size = 28\n",
    "num_classes = 10\n",
    "print(\"Training Dataset Size:\",train_num)\n",
    "print(\"Validation Dataset Size:\",valid_num)\n",
    "print(\"Testing Dataset Size:\",test_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-5bd8ca53c032>:5: calling argmax (from tensorflow.python.ops.math_ops) with dimension is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the `axis` argument instead\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "x = tf.placeholder(tf.float32, shape=[None, img_flatten], name='x')\n",
    "input_x = tf.reshape(x,[-1,img_size,img_size,1])\n",
    "y = tf.placeholder(tf.float32, shape=[None, num_classes], name='y')\n",
    "y_cls = tf.argmax(y,dimension=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-8e2b2b74f362>:1: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "WARNING:tensorflow:From /home/zhifant/.conda/envs/DL_HW1/lib/python3.6/site-packages/tensorflow_core/python/layers/convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From <ipython-input-4-8e2b2b74f362>:2: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.MaxPooling2D instead.\n",
      "WARNING:tensorflow:From <ipython-input-4-8e2b2b74f362>:5: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From <ipython-input-4-8e2b2b74f362>:6: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n"
     ]
    }
   ],
   "source": [
    "m1_conv1 = tf.layers.conv2d(inputs=input_x,filters=16,kernel_size=5,padding=\"same\",activation=tf.nn.relu,name='layer_conv1');\n",
    "m1_pool1 = tf.layers.max_pooling2d(inputs=m1_conv1,pool_size=2,strides=2);\n",
    "m1_conv2 = tf.layers.conv2d(inputs=m1_pool1,filters=36,kernel_size=5,padding=\"same\",activation=tf.nn.relu,name='layer_conv2');\n",
    "m1_pool2 = tf.layers.max_pooling2d(inputs=m1_conv2,pool_size=2,strides=2);\n",
    "m1_flat1 = tf.layers.flatten(m1_pool2);\n",
    "m1_fc1 = tf.layers.dense(inputs=m1_flat1,units=128,activation=tf.nn.relu, name='layer_fc1');\n",
    "m1_logits = tf.layers.dense(inputs=m1_fc1,units=num_classes,activation=None, name='layer_fc_out');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-1ba7c95ec200>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cross Entropy Loss\n",
    "m1_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=m1_logits);\n",
    "m1_loss = tf.reduce_mean(m1_cross_entropy);\n",
    "\n",
    "# Accuracy\n",
    "m1_softmax = tf.nn.softmax(logits=m1_logits);\n",
    "m1_pred_op = tf.argmax(m1_softmax,dimension=1);\n",
    "m1_acc_op = tf.reduce_mean(tf.cast(tf.equal(m1_pred_op, y_cls), tf.float32));\n",
    "\n",
    "# Optimizer and Training Operation\n",
    "m1_optimizer = tf.train.AdamOptimizer(learning_rate=0.0001);\n",
    "m1_train_op = m1_optimizer.minimize(m1_loss);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model on MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = data.train.images\n",
    "y_train = data.train.labels\n",
    "np.random.shuffle(y_train)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createBatches(train_x,train_y,batch_size):\n",
    "    mini_batches = []\n",
    "    data_num = train_x.shape[0]\n",
    "    idx = np.arange(data_num)\n",
    "    np.random.shuffle(idx)\n",
    "    train_x = train_x[idx]\n",
    "    train_y = train_y[idx]\n",
    "    for i in range(0,data_num-batch_size,batch_size):\n",
    "        x = train_x[i:i+batch_size]\n",
    "        y = train_y[i:i+batch_size]\n",
    "        mini_batches.append((x,y))\n",
    "    if data_num % batch_size != 0:\n",
    "        x = train_x[i+batch_size:data_num]\n",
    "        y = train_y[i+batch_size:data_num]\n",
    "        mini_batches.append((x,y))\n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 Train Loss:  2.2889698 Test Loss:  2.3094218 Test acc:  0.1228\n",
      "Epoch:  5 Train Loss:  2.3199172 Test Loss:  2.3291793 Test acc:  0.1252\n",
      "Epoch:  10 Train Loss:  2.2838213 Test Loss:  2.3151019 Test acc:  0.1307\n",
      "Epoch:  15 Train Loss:  2.243975 Test Loss:  2.369332 Test acc:  0.0782\n",
      "Epoch:  20 Train Loss:  2.2422922 Test Loss:  2.395967 Test acc:  0.0846\n",
      "Epoch:  25 Train Loss:  2.195062 Test Loss:  2.400376 Test acc:  0.1046\n",
      "Epoch:  30 Train Loss:  1.9118671 Test Loss:  2.4619234 Test acc:  0.101\n",
      "Epoch:  35 Train Loss:  1.9112679 Test Loss:  2.5428278 Test acc:  0.0979\n",
      "Epoch:  40 Train Loss:  1.8142844 Test Loss:  2.5742605 Test acc:  0.0958\n",
      "Epoch:  45 Train Loss:  1.8218864 Test Loss:  2.5986595 Test acc:  0.099\n",
      "Epoch:  50 Train Loss:  1.6683458 Test Loss:  2.6812994 Test acc:  0.1026\n",
      "Epoch:  55 Train Loss:  2.0656564 Test Loss:  2.7991543 Test acc:  0.0863\n",
      "Epoch:  60 Train Loss:  1.6934271 Test Loss:  2.8589437 Test acc:  0.0964\n",
      "Epoch:  65 Train Loss:  1.4583842 Test Loss:  2.8652809 Test acc:  0.1087\n",
      "Epoch:  70 Train Loss:  1.760295 Test Loss:  3.0079703 Test acc:  0.0897\n",
      "Epoch:  75 Train Loss:  1.6277632 Test Loss:  3.0765052 Test acc:  0.0992\n",
      "Epoch:  80 Train Loss:  1.066974 Test Loss:  3.1837008 Test acc:  0.1052\n",
      "Epoch:  85 Train Loss:  1.376708 Test Loss:  3.1739793 Test acc:  0.1078\n",
      "Epoch:  90 Train Loss:  1.1330789 Test Loss:  3.2861023 Test acc:  0.1059\n",
      "Epoch:  95 Train Loss:  1.2934357 Test Loss:  3.4246187 Test acc:  0.0989\n",
      "Epoch:  100 Train Loss:  1.2691807 Test Loss:  3.4854758 Test acc:  0.1056\n",
      "Epoch:  105 Train Loss:  1.4531212 Test Loss:  3.5369859 Test acc:  0.1083\n",
      "Epoch:  110 Train Loss:  1.1496187 Test Loss:  3.7341228 Test acc:  0.1047\n",
      "Epoch:  115 Train Loss:  0.9161672 Test Loss:  3.8553073 Test acc:  0.101\n",
      "Epoch:  120 Train Loss:  1.1588861 Test Loss:  3.918125 Test acc:  0.1113\n",
      "Epoch:  125 Train Loss:  0.9481516 Test Loss:  4.2324095 Test acc:  0.0951\n",
      "Epoch:  130 Train Loss:  0.8875205 Test Loss:  4.3105264 Test acc:  0.1023\n",
      "Epoch:  135 Train Loss:  0.62540513 Test Loss:  4.4097543 Test acc:  0.1011\n",
      "Epoch:  140 Train Loss:  0.84523463 Test Loss:  4.497829 Test acc:  0.1016\n",
      "Epoch:  145 Train Loss:  0.6199905 Test Loss:  4.7899776 Test acc:  0.0916\n",
      "Epoch:  150 Train Loss:  0.42691973 Test Loss:  4.837003 Test acc:  0.1061\n",
      "Epoch:  155 Train Loss:  0.7183425 Test Loss:  4.9494205 Test acc:  0.1057\n",
      "Epoch:  160 Train Loss:  0.4857644 Test Loss:  5.120624 Test acc:  0.1061\n",
      "Epoch:  165 Train Loss:  0.62661904 Test Loss:  5.3823276 Test acc:  0.0988\n",
      "Epoch:  170 Train Loss:  0.6973944 Test Loss:  5.6859603 Test acc:  0.0928\n",
      "Epoch:  175 Train Loss:  0.49288404 Test Loss:  5.7300205 Test acc:  0.1011\n",
      "Epoch:  180 Train Loss:  0.66486144 Test Loss:  6.099361 Test acc:  0.0896\n",
      "Epoch:  185 Train Loss:  0.85480016 Test Loss:  6.238577 Test acc:  0.0997\n",
      "Epoch:  190 Train Loss:  0.4008241 Test Loss:  6.3376927 Test acc:  0.0968\n",
      "Epoch:  195 Train Loss:  0.57986015 Test Loss:  6.675588 Test acc:  0.102\n",
      "Epoch:  200 Train Loss:  0.49030152 Test Loss:  6.751533 Test acc:  0.0975\n",
      "Epoch:  205 Train Loss:  0.52288795 Test Loss:  7.0757103 Test acc:  0.098\n",
      "Epoch:  210 Train Loss:  0.32353058 Test Loss:  7.302031 Test acc:  0.1056\n",
      "Epoch:  215 Train Loss:  0.33175632 Test Loss:  7.4484453 Test acc:  0.0939\n",
      "Epoch:  220 Train Loss:  0.3493289 Test Loss:  7.6707845 Test acc:  0.0969\n",
      "Epoch:  225 Train Loss:  0.30882558 Test Loss:  7.7965813 Test acc:  0.103\n",
      "Epoch:  230 Train Loss:  0.32914475 Test Loss:  8.098986 Test acc:  0.0985\n",
      "Epoch:  235 Train Loss:  0.2469217 Test Loss:  8.437012 Test acc:  0.0965\n",
      "Epoch:  240 Train Loss:  0.11334694 Test Loss:  8.515464 Test acc:  0.1106\n",
      "Epoch:  245 Train Loss:  0.20695962 Test Loss:  8.896158 Test acc:  0.095\n",
      "Epoch:  250 Train Loss:  0.31587982 Test Loss:  9.281404 Test acc:  0.1021\n",
      "Epoch:  255 Train Loss:  0.291888 Test Loss:  9.396825 Test acc:  0.0986\n",
      "Epoch:  260 Train Loss:  0.10343694 Test Loss:  9.694388 Test acc:  0.0933\n",
      "Epoch:  265 Train Loss:  0.22216101 Test Loss:  9.695105 Test acc:  0.1089\n",
      "Epoch:  270 Train Loss:  0.19141601 Test Loss:  10.130913 Test acc:  0.0987\n",
      "Epoch:  275 Train Loss:  0.16931815 Test Loss:  10.30074 Test acc:  0.0989\n",
      "Epoch:  280 Train Loss:  0.09150022 Test Loss:  10.420262 Test acc:  0.0982\n",
      "Epoch:  285 Train Loss:  0.22232355 Test Loss:  10.7096405 Test acc:  0.0999\n",
      "Epoch:  290 Train Loss:  0.07967485 Test Loss:  11.008325 Test acc:  0.0924\n",
      "Epoch:  295 Train Loss:  0.09650016 Test Loss:  11.256186 Test acc:  0.0968\n",
      "Epoch:  300 Train Loss:  0.07992977 Test Loss:  11.460818 Test acc:  0.1044\n",
      "Epoch:  305 Train Loss:  0.04322989 Test Loss:  11.632568 Test acc:  0.0961\n",
      "Epoch:  310 Train Loss:  0.1315128 Test Loss:  11.988797 Test acc:  0.1024\n",
      "Epoch:  315 Train Loss:  0.037924442 Test Loss:  12.173715 Test acc:  0.0957\n",
      "Epoch:  320 Train Loss:  0.056753516 Test Loss:  12.395017 Test acc:  0.1017\n",
      "Epoch:  325 Train Loss:  0.13445836 Test Loss:  12.645998 Test acc:  0.098\n",
      "Epoch:  330 Train Loss:  0.1335265 Test Loss:  12.7780905 Test acc:  0.0943\n",
      "Epoch:  335 Train Loss:  0.02660247 Test Loss:  13.188496 Test acc:  0.0938\n",
      "Epoch:  340 Train Loss:  0.07251792 Test Loss:  13.367525 Test acc:  0.1012\n",
      "Epoch:  345 Train Loss:  0.029970674 Test Loss:  13.332291 Test acc:  0.1002\n",
      "Epoch:  350 Train Loss:  0.101180576 Test Loss:  13.423285 Test acc:  0.0997\n",
      "Epoch:  355 Train Loss:  0.08336697 Test Loss:  13.78384 Test acc:  0.0956\n",
      "Epoch:  360 Train Loss:  0.024068182 Test Loss:  13.914713 Test acc:  0.1022\n",
      "Epoch:  365 Train Loss:  0.29985487 Test Loss:  14.063483 Test acc:  0.094\n",
      "Epoch:  370 Train Loss:  0.05144759 Test Loss:  14.401944 Test acc:  0.0966\n",
      "Epoch:  375 Train Loss:  0.055122036 Test Loss:  14.458347 Test acc:  0.094\n",
      "Epoch:  380 Train Loss:  0.14223914 Test Loss:  14.4448185 Test acc:  0.1031\n"
     ]
    }
   ],
   "source": [
    "session = tf.Session() \n",
    "session.run(tf.global_variables_initializer())         # initialize var in graph\n",
    "EPOCH = 1000\n",
    "BATCH_SIZE = 64\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_loss_list = []\n",
    "test_acc_list = []\n",
    "for i in range(EPOCH):\n",
    "    batches = createBatches(x_train,y_train,BATCH_SIZE)\n",
    "    for batch in batches:\n",
    "        x_batch, y_true_batch = batch\n",
    "        session.run(m1_train_op, feed_dict={x: x_batch,y: y_true_batch})\n",
    "    train_loss, train_acc = session.run([m1_loss,m1_acc_op], feed_dict={x: x_batch,y: y_true_batch})\n",
    "    train_loss_list.append(train_loss)\n",
    "    train_acc_list.append(train_acc)\n",
    "    test_loss, test_acc = session.run([m1_loss,m1_acc_op],feed_dict={x:data.test.images,y:data.test.labels})\n",
    "    test_loss_list.append(test_loss)\n",
    "    test_acc_list.append(test_acc)\n",
    "    if i%5 == 0:\n",
    "        print(\"Epoch: \",i,\"Train Loss: \",train_loss,\"Test Loss: \",test_loss,\"Test acc: \",test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_HW1",
   "language": "python",
   "name": "dl_hw1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
