{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ** CPSC 8810 Deep Learning - HW1-3 **\n",
    "---\n",
    "\n",
    "## Introduction\n",
    "_**Note:** This assignment makes use of the MNIST dataset_\n",
    "\n",
    "The main objective of this assignments:\n",
    "* Fit network with random labels\n",
    "* Compare number of parameters vs generalization\n",
    "* Compare flatness vs generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "tf.__version__\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Dataset Preparation and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-2cdd42740c4c>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/zhifant/.conda/envs/DL_HW1/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/zhifant/.conda/envs/DL_HW1/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/MNIST/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/zhifant/.conda/envs/DL_HW1/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/MNIST/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/zhifant/.conda/envs/DL_HW1/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting data/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/zhifant/.conda/envs/DL_HW1/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "Training Dataset Size: 55000\n",
      "Validation Dataset Size: 5000\n",
      "Testing Dataset Size: 10000\n"
     ]
    }
   ],
   "source": [
    "data = input_data.read_data_sets('data/MNIST/', one_hot=True);\n",
    "\n",
    "train_num = data.train.num_examples\n",
    "valid_num = data.validation.num_examples\n",
    "test_num = data.test.num_examples\n",
    "img_flatten = 784\n",
    "img_size = 28\n",
    "num_classes = 10\n",
    "print(\"Training Dataset Size:\",train_num)\n",
    "print(\"Validation Dataset Size:\",valid_num)\n",
    "print(\"Testing Dataset Size:\",test_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAApsAAAD3CAYAAABSO59sAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 864x288 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(2,5)\n",
    "fig.set_size_inches(12,4)\n",
    "for i in range(10):\n",
    "    idx = np.where(np.argmax(data.train.labels,1)==i)[0][0]\n",
    "    axs[int(i/5),i%5].imshow(data.train.images[idx].reshape(28,28))\n",
    "    axs[int(i/5),i%5].set_title(str(i))\n",
    "    axs[int(i/5),i%5].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CIFAR-10 Data Distribution Before Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlwAAAE/CAYAAACTlB3ZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSZ0ZuCRJkjr7/6SEQMkUr5kaAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bar_fig = plt.figure(figsize=[10,5])\n",
    "unique, counts = np.unique(np.argmax(data.train.labels,1), return_counts=True)\n",
    "plt.bar(unique,counts)\n",
    "plt.title(\"Data Distribution Before Data Augmentation\")\n",
    "plt.xticks(unique,np.arange(10));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Count Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameter_count():\n",
    "    total_parameters = 0\n",
    "    for variable in tf.trainable_variables():\n",
    "        print(variable)\n",
    "        shape = variable.get_shape()\n",
    "        variable_parameters = 1\n",
    "        for dim in shape:\n",
    "            variable_parameters *= dim.value\n",
    "        #print(\"parameter num:\",variable_parameters)\n",
    "        total_parameters += variable_parameters\n",
    "    print(\"Total Parameter: \",total_parameters)\n",
    "    return total_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Model 1 Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'conv2d/kernel:0' shape=(5, 5, 1, 16) dtype=float32_ref>\n",
      "<tf.Variable 'conv2d/bias:0' shape=(16,) dtype=float32_ref>\n",
      "<tf.Variable 'conv2d_1/kernel:0' shape=(5, 5, 16, 36) dtype=float32_ref>\n",
      "<tf.Variable 'conv2d_1/bias:0' shape=(36,) dtype=float32_ref>\n",
      "<tf.Variable 'dense/kernel:0' shape=(1764, 128) dtype=float32_ref>\n",
      "<tf.Variable 'dense/bias:0' shape=(128,) dtype=float32_ref>\n",
      "<tf.Variable 'dense_1/kernel:0' shape=(128, 10) dtype=float32_ref>\n",
      "<tf.Variable 'dense_1/bias:0' shape=(10,) dtype=float32_ref>\n",
      "Total Parameter:  242062\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "x = tf.placeholder(tf.float32, shape=[None, img_flatten], name='x')\n",
    "input_x = tf.reshape(x,[-1,img_size,img_size,1])\n",
    "y = tf.placeholder(tf.float32, shape=[None, num_classes], name='y')\n",
    "y_cls = tf.argmax(y,dimension=1)\n",
    "\n",
    "conv1 = tf.layers.conv2d(inputs=input_x,filters=16,kernel_size=5,padding=\"same\",activation=tf.nn.relu);\n",
    "pool1 = tf.layers.max_pooling2d(inputs=conv1,pool_size=2,strides=2);\n",
    "conv2 = tf.layers.conv2d(inputs=pool1,filters=36,kernel_size=5,padding=\"same\",activation=tf.nn.relu);\n",
    "pool2 = tf.layers.max_pooling2d(inputs=conv2,pool_size=2,strides=2);\n",
    "flat1 = tf.layers.flatten(pool2);\n",
    "fc1 = tf.layers.dense(inputs=flat1,units=128,activation=tf.nn.relu);\n",
    "logits = tf.layers.dense(inputs=fc1,units=num_classes,activation=None);\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=logits);\n",
    "loss = tf.reduce_mean(cross_entropy);\n",
    "\n",
    "# Accuracy\n",
    "softmax = tf.nn.softmax(logits=logits);\n",
    "pred_op = tf.argmax(softmax,dimension=1);\n",
    "acc_op = tf.reduce_mean(tf.cast(tf.equal(pred_op, y_cls), tf.float32));\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.005);\n",
    "train_op = optimizer.minimize(loss);\n",
    "\n",
    "param1 = parameter_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Training Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:      0, Training Loss: 0.00448694, Training Accuracy: 100.0%, Test Loss: 0.0443865, Test Accuracy:  98.4%\n",
      "Epoch:      1, Training Loss: 0.0102419, Training Accuracy: 100.0%, Test Loss: 0.0417959, Test Accuracy:  98.8%\n",
      "Epoch:      2, Training Loss: 0.00716345, Training Accuracy: 100.0%, Test Loss: 0.0364437, Test Accuracy:  98.9%\n",
      "Epoch:      3, Training Loss: 0.00271016, Training Accuracy: 100.0%, Test Loss: 0.0595672, Test Accuracy:  98.4%\n",
      "Epoch:      4, Training Loss: 0.0058798, Training Accuracy: 100.0%, Test Loss: 0.0502747, Test Accuracy:  98.7%\n"
     ]
    }
   ],
   "source": [
    "train_loss_list1 = []\n",
    "train_acc_list1 = []\n",
    "test_loss_list1 = []\n",
    "test_acc_list1 = []\n",
    "\n",
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EPOCH = 5\n",
    "for i in range(EPOCH):\n",
    "    for j in range(int(data.train.num_examples/BATCH_SIZE)):\n",
    "\n",
    "        x_batch, y_true_batch = data.train.next_batch(BATCH_SIZE)\n",
    "        \n",
    "        session.run(train_op, feed_dict={x: x_batch,y: y_true_batch})\n",
    "    train_loss, train_acc = session.run([loss,acc_op],feed_dict={x:x_batch,y:y_true_batch})\n",
    "    train_loss_list1.append(train_loss)\n",
    "    train_acc_list1.append(train_acc)\n",
    "    test_loss, test_acc = session.run([loss,acc_op],feed_dict={x:data.test.images,y:data.test.labels})\n",
    "    test_loss_list1.append(test_loss)\n",
    "    test_acc_list1.append(test_acc)\n",
    "    msg = \"Epoch: {0:>6}, Training Loss: {1:>1.6}, Training Accuracy: {2:>6.1%}, Test Loss: {3:>1.6}, Test Accuracy: {4:>6.1%}\"\n",
    "    print(msg.format(i, train_loss, train_acc, test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 2.1 Model 2 Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'conv2d/kernel:0' shape=(5, 5, 1, 16) dtype=float32_ref>\n",
      "<tf.Variable 'conv2d/bias:0' shape=(16,) dtype=float32_ref>\n",
      "<tf.Variable 'conv2d_1/kernel:0' shape=(5, 5, 16, 36) dtype=float32_ref>\n",
      "<tf.Variable 'conv2d_1/bias:0' shape=(36,) dtype=float32_ref>\n",
      "<tf.Variable 'dense/kernel:0' shape=(1764, 10) dtype=float32_ref>\n",
      "<tf.Variable 'dense/bias:0' shape=(10,) dtype=float32_ref>\n",
      "<tf.Variable 'dense_1/kernel:0' shape=(10, 10) dtype=float32_ref>\n",
      "<tf.Variable 'dense_1/bias:0' shape=(10,) dtype=float32_ref>\n",
      "Total Parameter:  32612\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "x = tf.placeholder(tf.float32, shape=[None, img_flatten], name='x')\n",
    "input_x = tf.reshape(x,[-1,img_size,img_size,1])\n",
    "y = tf.placeholder(tf.float32, shape=[None, num_classes], name='y')\n",
    "y_cls = tf.argmax(y,dimension=1)\n",
    "\n",
    "conv1 = tf.layers.conv2d(inputs=input_x,filters=16,kernel_size=5,padding=\"same\",activation=tf.nn.relu);\n",
    "pool1 = tf.layers.max_pooling2d(inputs=conv1,pool_size=2,strides=2);\n",
    "conv2 = tf.layers.conv2d(inputs=pool1,filters=36,kernel_size=5,padding=\"same\",activation=tf.nn.relu);\n",
    "pool2 = tf.layers.max_pooling2d(inputs=conv2,pool_size=2,strides=2);\n",
    "flat1 = tf.layers.flatten(pool2);\n",
    "fc1 = tf.layers.dense(inputs=flat1,units=10,activation=tf.nn.relu);\n",
    "logits = tf.layers.dense(inputs=fc1,units=num_classes,activation=None);\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=logits);\n",
    "loss = tf.reduce_mean(cross_entropy);\n",
    "\n",
    "# Accuracy\n",
    "softmax = tf.nn.softmax(logits=logits);\n",
    "pred_op = tf.argmax(softmax,dimension=1);\n",
    "acc_op = tf.reduce_mean(tf.cast(tf.equal(pred_op, y_cls), tf.float32));\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.005);\n",
    "train_op = optimizer.minimize(loss);\n",
    "\n",
    "param2 = parameter_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Model 2 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:      0, Training Loss: 0.1107, Training Accuracy:  95.3%, Test Loss: 0.0864624, Test Accuracy:  97.5%\n",
      "Epoch:      1, Training Loss: 0.00826876, Training Accuracy: 100.0%, Test Loss: 0.0542757, Test Accuracy:  98.4%\n",
      "Epoch:      2, Training Loss: 0.0418426, Training Accuracy:  98.4%, Test Loss: 0.0504898, Test Accuracy:  98.5%\n",
      "Epoch:      3, Training Loss: 0.0224819, Training Accuracy: 100.0%, Test Loss: 0.0483079, Test Accuracy:  98.7%\n",
      "Epoch:      4, Training Loss: 0.0331357, Training Accuracy:  98.4%, Test Loss: 0.0534633, Test Accuracy:  98.7%\n"
     ]
    }
   ],
   "source": [
    "train_loss_list2 = []\n",
    "train_acc_list2 = []\n",
    "test_loss_list2 = []\n",
    "test_acc_list2 = []\n",
    "\n",
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EPOCH = 5\n",
    "for i in range(EPOCH):\n",
    "    for j in range(int(data.train.num_examples/BATCH_SIZE)):\n",
    "\n",
    "        x_batch, y_true_batch = data.train.next_batch(BATCH_SIZE)\n",
    "        \n",
    "        session.run(train_op, feed_dict={x: x_batch,y: y_true_batch})\n",
    "    train_loss, train_acc = session.run([loss,acc_op],feed_dict={x:x_batch,y:y_true_batch})\n",
    "    train_loss_list2.append(train_loss)\n",
    "    train_acc_list2.append(train_acc)\n",
    "    test_loss, test_acc = session.run([loss,acc_op],feed_dict={x:data.test.images,y:data.test.labels})\n",
    "    test_loss_list2.append(test_loss)\n",
    "    test_acc_list2.append(test_acc)\n",
    "    msg = \"Epoch: {0:>6}, Training Loss: {1:>1.6}, Training Accuracy: {2:>6.1%}, Test Loss: {3:>1.6}, Test Accuracy: {4:>6.1%}\"\n",
    "    print(msg.format(i, train_loss, train_acc, test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 3.1 Model 3 Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'conv2d/kernel:0' shape=(5, 5, 1, 16) dtype=float32_ref>\n",
      "<tf.Variable 'conv2d/bias:0' shape=(16,) dtype=float32_ref>\n",
      "<tf.Variable 'conv2d_1/kernel:0' shape=(5, 5, 16, 24) dtype=float32_ref>\n",
      "<tf.Variable 'conv2d_1/bias:0' shape=(24,) dtype=float32_ref>\n",
      "<tf.Variable 'dense/kernel:0' shape=(1176, 10) dtype=float32_ref>\n",
      "<tf.Variable 'dense/bias:0' shape=(10,) dtype=float32_ref>\n",
      "<tf.Variable 'dense_1/kernel:0' shape=(10, 10) dtype=float32_ref>\n",
      "<tf.Variable 'dense_1/bias:0' shape=(10,) dtype=float32_ref>\n",
      "Total Parameter:  21920\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "x = tf.placeholder(tf.float32, shape=[None, img_flatten], name='x')\n",
    "input_x = tf.reshape(x,[-1,img_size,img_size,1])\n",
    "y = tf.placeholder(tf.float32, shape=[None, num_classes], name='y')\n",
    "y_cls = tf.argmax(y,dimension=1)\n",
    "\n",
    "conv1 = tf.layers.conv2d(inputs=input_x,filters=16,kernel_size=5,padding=\"same\",activation=tf.nn.relu);\n",
    "pool1 = tf.layers.max_pooling2d(inputs=conv1,pool_size=2,strides=2);\n",
    "conv2 = tf.layers.conv2d(inputs=pool1,filters=24,kernel_size=5,padding=\"same\",activation=tf.nn.relu);\n",
    "pool2 = tf.layers.max_pooling2d(inputs=conv2,pool_size=2,strides=2);\n",
    "flat1 = tf.layers.flatten(pool2);\n",
    "fc1 = tf.layers.dense(inputs=flat1,units=10,activation=tf.nn.relu);\n",
    "logits = tf.layers.dense(inputs=fc1,units=num_classes,activation=None);\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=logits);\n",
    "loss = tf.reduce_mean(cross_entropy);\n",
    "\n",
    "# Accuracy\n",
    "softmax = tf.nn.softmax(logits=logits);\n",
    "pred_op = tf.argmax(softmax,dimension=1);\n",
    "acc_op = tf.reduce_mean(tf.cast(tf.equal(pred_op, y_cls), tf.float32));\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.005);\n",
    "train_op = optimizer.minimize(loss);\n",
    "\n",
    "param3 = parameter_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Model 3 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:      0, Training Loss: 0.00807396, Training Accuracy: 100.0%, Test Loss: 0.0677661, Test Accuracy:  98.0%\n",
      "Epoch:      1, Training Loss: 0.00583127, Training Accuracy: 100.0%, Test Loss: 0.0621058, Test Accuracy:  98.1%\n",
      "Epoch:      2, Training Loss: 0.023459, Training Accuracy: 100.0%, Test Loss: 0.0719958, Test Accuracy:  97.7%\n",
      "Epoch:      3, Training Loss: 0.0370454, Training Accuracy:  98.4%, Test Loss: 0.0573608, Test Accuracy:  98.4%\n",
      "Epoch:      4, Training Loss: 0.115823, Training Accuracy:  96.9%, Test Loss: 0.049702, Test Accuracy:  98.6%\n"
     ]
    }
   ],
   "source": [
    "train_loss_list3= []\n",
    "train_acc_list3 = []\n",
    "test_loss_list3 = []\n",
    "test_acc_list3 = []\n",
    "\n",
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EPOCH = 5\n",
    "for i in range(EPOCH):\n",
    "    for j in range(int(data.train.num_examples/BATCH_SIZE)):\n",
    "\n",
    "        x_batch, y_true_batch = data.train.next_batch(BATCH_SIZE)\n",
    "        \n",
    "        session.run(train_op, feed_dict={x: x_batch,y: y_true_batch})\n",
    "    train_loss, train_acc = session.run([loss,acc_op],feed_dict={x:x_batch,y:y_true_batch})\n",
    "    test_loss, test_acc = session.run([loss,acc_op],feed_dict={x:data.test.images,y:data.test.labels})\n",
    "    train_loss_list3.append(train_loss)\n",
    "    train_acc_list3.append(train_acc)\n",
    "    test_loss_list3.append(test_loss)\n",
    "    test_acc_list3.append(test_acc)\n",
    "    msg = \"Epoch: {0:>6}, Training Loss: {1:>1.6}, Training Accuracy: {2:>6.1%}, Test Loss: {3:>1.6}, Test Accuracy: {4:>6.1%}\"\n",
    "    print(msg.format(i, train_loss, train_acc, test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 4.1 Model 4 Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'conv2d/kernel:0' shape=(5, 5, 1, 8) dtype=float32_ref>\n",
      "<tf.Variable 'conv2d/bias:0' shape=(8,) dtype=float32_ref>\n",
      "<tf.Variable 'conv2d_1/kernel:0' shape=(5, 5, 8, 24) dtype=float32_ref>\n",
      "<tf.Variable 'conv2d_1/bias:0' shape=(24,) dtype=float32_ref>\n",
      "<tf.Variable 'dense/kernel:0' shape=(1176, 10) dtype=float32_ref>\n",
      "<tf.Variable 'dense/bias:0' shape=(10,) dtype=float32_ref>\n",
      "<tf.Variable 'dense_1/kernel:0' shape=(10, 10) dtype=float32_ref>\n",
      "<tf.Variable 'dense_1/bias:0' shape=(10,) dtype=float32_ref>\n",
      "Total Parameter:  16912\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "x = tf.placeholder(tf.float32, shape=[None, img_flatten], name='x')\n",
    "input_x = tf.reshape(x,[-1,img_size,img_size,1])\n",
    "y = tf.placeholder(tf.float32, shape=[None, num_classes], name='y')\n",
    "y_cls = tf.argmax(y,dimension=1)\n",
    "\n",
    "conv1 = tf.layers.conv2d(inputs=input_x,filters=8,kernel_size=5,padding=\"same\",activation=tf.nn.relu);\n",
    "pool1 = tf.layers.max_pooling2d(inputs=conv1,pool_size=2,strides=2);\n",
    "conv2 = tf.layers.conv2d(inputs=pool1,filters=24,kernel_size=5,padding=\"same\",activation=tf.nn.relu);\n",
    "pool2 = tf.layers.max_pooling2d(inputs=conv2,pool_size=2,strides=2);\n",
    "flat1 = tf.layers.flatten(pool2);\n",
    "fc1 = tf.layers.dense(inputs=flat1,units=10,activation=tf.nn.relu);\n",
    "logits = tf.layers.dense(inputs=fc1,units=num_classes,activation=None);\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=logits);\n",
    "loss = tf.reduce_mean(cross_entropy);\n",
    "\n",
    "# Accuracy\n",
    "softmax = tf.nn.softmax(logits=logits);\n",
    "pred_op = tf.argmax(softmax,dimension=1);\n",
    "acc_op = tf.reduce_mean(tf.cast(tf.equal(pred_op, y_cls), tf.float32));\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.005);\n",
    "train_op = optimizer.minimize(loss);\n",
    "\n",
    "param4 = parameter_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Model 4 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:      0, Training Loss: 0.066006, Training Accuracy:  98.4%, Test Loss: 0.0609542, Test Accuracy:  98.2%\n",
      "Epoch:      1, Training Loss: 0.0535932, Training Accuracy:  96.9%, Test Loss: 0.0603344, Test Accuracy:  98.1%\n",
      "Epoch:      2, Training Loss: 0.0090453, Training Accuracy: 100.0%, Test Loss: 0.0667324, Test Accuracy:  97.9%\n",
      "Epoch:      3, Training Loss: 0.0220817, Training Accuracy: 100.0%, Test Loss: 0.0492585, Test Accuracy:  98.6%\n",
      "Epoch:      4, Training Loss: 0.0468952, Training Accuracy:  96.9%, Test Loss: 0.0482411, Test Accuracy:  98.7%\n"
     ]
    }
   ],
   "source": [
    "train_loss_list4= []\n",
    "train_acc_list4 = []\n",
    "test_loss_list4 = []\n",
    "test_acc_list4 = []\n",
    "\n",
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EPOCH = 5\n",
    "for i in range(EPOCH):\n",
    "    for j in range(int(data.train.num_examples/BATCH_SIZE)):\n",
    "\n",
    "        x_batch, y_true_batch = data.train.next_batch(BATCH_SIZE)\n",
    "        \n",
    "        session.run(train_op, feed_dict={x: x_batch,y: y_true_batch})\n",
    "    train_loss, train_acc = session.run([loss,acc_op],feed_dict={x:x_batch,y:y_true_batch})\n",
    "    test_loss, test_acc = session.run([loss,acc_op],feed_dict={x:data.test.images,y:data.test.labels})\n",
    "    train_loss_list4.append(train_loss)\n",
    "    train_acc_list4.append(train_acc)\n",
    "    test_loss_list4.append(test_loss)\n",
    "    test_acc_list4.append(test_acc)\n",
    "    msg = \"Epoch: {0:>6}, Training Loss: {1:>1.6}, Training Accuracy: {2:>6.1%}, Test Loss: {3:>1.6}, Test Accuracy: {4:>6.1%}\"\n",
    "    print(msg.format(i, train_loss, train_acc, test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 5.1 Model 5 Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'conv2d/kernel:0' shape=(5, 5, 1, 8) dtype=float32_ref>\n",
      "<tf.Variable 'conv2d/bias:0' shape=(8,) dtype=float32_ref>\n",
      "<tf.Variable 'conv2d_1/kernel:0' shape=(5, 5, 8, 20) dtype=float32_ref>\n",
      "<tf.Variable 'conv2d_1/bias:0' shape=(20,) dtype=float32_ref>\n",
      "<tf.Variable 'dense/kernel:0' shape=(980, 10) dtype=float32_ref>\n",
      "<tf.Variable 'dense/bias:0' shape=(10,) dtype=float32_ref>\n",
      "<tf.Variable 'dense_1/kernel:0' shape=(10, 10) dtype=float32_ref>\n",
      "<tf.Variable 'dense_1/bias:0' shape=(10,) dtype=float32_ref>\n",
      "Total Parameter:  14148\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "x = tf.placeholder(tf.float32, shape=[None, img_flatten], name='x')\n",
    "input_x = tf.reshape(x,[-1,img_size,img_size,1])\n",
    "y = tf.placeholder(tf.float32, shape=[None, num_classes], name='y')\n",
    "y_cls = tf.argmax(y,dimension=1)\n",
    "\n",
    "conv1 = tf.layers.conv2d(inputs=input_x,filters=8,kernel_size=5,padding=\"same\",activation=tf.nn.relu);\n",
    "pool1 = tf.layers.max_pooling2d(inputs=conv1,pool_size=2,strides=2);\n",
    "conv2 = tf.layers.conv2d(inputs=pool1,filters=20,kernel_size=5,padding=\"same\",activation=tf.nn.relu);\n",
    "pool2 = tf.layers.max_pooling2d(inputs=conv2,pool_size=2,strides=2);\n",
    "flat1 = tf.layers.flatten(pool2);\n",
    "fc1 = tf.layers.dense(inputs=flat1,units=10,activation=tf.nn.relu);\n",
    "logits = tf.layers.dense(inputs=fc1,units=num_classes,activation=None);\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=logits);\n",
    "loss = tf.reduce_mean(cross_entropy);\n",
    "\n",
    "# Accuracy\n",
    "softmax = tf.nn.softmax(logits=logits);\n",
    "pred_op = tf.argmax(softmax,dimension=1);\n",
    "acc_op = tf.reduce_mean(tf.cast(tf.equal(pred_op, y_cls), tf.float32));\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.005);\n",
    "train_op = optimizer.minimize(loss);\n",
    "\n",
    "param5 = parameter_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Model 5 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:      0, Training Loss: 0.0773063, Training Accuracy:  96.9%, Test Loss: 0.0549455, Test Accuracy:  98.2%\n",
      "Epoch:      1, Training Loss: 0.00737932, Training Accuracy: 100.0%, Test Loss: 0.0524945, Test Accuracy:  98.5%\n",
      "Epoch:      2, Training Loss: 0.0348139, Training Accuracy:  96.9%, Test Loss: 0.0423364, Test Accuracy:  98.6%\n",
      "Epoch:      3, Training Loss: 0.0890925, Training Accuracy:  95.3%, Test Loss: 0.0570298, Test Accuracy:  98.3%\n",
      "Epoch:      4, Training Loss: 0.0295076, Training Accuracy:  98.4%, Test Loss: 0.0484192, Test Accuracy:  98.5%\n"
     ]
    }
   ],
   "source": [
    "train_loss_list5= []\n",
    "train_acc_list5 = []\n",
    "test_loss_list5 = []\n",
    "test_acc_list5 = []\n",
    "\n",
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EPOCH = 5\n",
    "for i in range(EPOCH):\n",
    "    for j in range(int(data.train.num_examples/BATCH_SIZE)):\n",
    "\n",
    "        x_batch, y_true_batch = data.train.next_batch(BATCH_SIZE)\n",
    "        \n",
    "        session.run(train_op, feed_dict={x: x_batch,y: y_true_batch})\n",
    "    train_loss, train_acc = session.run([loss,acc_op],feed_dict={x:x_batch,y:y_true_batch})\n",
    "    test_loss, test_acc = session.run([loss,acc_op],feed_dict={x:data.test.images,y:data.test.labels})\n",
    "    train_loss_list5.append(train_loss)\n",
    "    train_acc_list5.append(train_acc)\n",
    "    test_loss_list5.append(test_loss)\n",
    "    test_acc_list5.append(test_acc)\n",
    "    msg = \"Epoch: {0:>6}, Training Loss: {1:>1.6}, Training Accuracy: {2:>6.1%}, Test Loss: {3:>1.6}, Test Accuracy: {4:>6.1%}\"\n",
    "    print(msg.format(i, train_loss, train_acc, test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 6.1 Model 6 Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'conv2d/kernel:0' shape=(5, 5, 1, 8) dtype=float32_ref>\n",
      "<tf.Variable 'conv2d/bias:0' shape=(8,) dtype=float32_ref>\n",
      "<tf.Variable 'conv2d_1/kernel:0' shape=(5, 5, 8, 15) dtype=float32_ref>\n",
      "<tf.Variable 'conv2d_1/bias:0' shape=(15,) dtype=float32_ref>\n",
      "<tf.Variable 'dense/kernel:0' shape=(735, 10) dtype=float32_ref>\n",
      "<tf.Variable 'dense/bias:0' shape=(10,) dtype=float32_ref>\n",
      "<tf.Variable 'dense_1/kernel:0' shape=(10, 10) dtype=float32_ref>\n",
      "<tf.Variable 'dense_1/bias:0' shape=(10,) dtype=float32_ref>\n",
      "Total Parameter:  10693\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "x = tf.placeholder(tf.float32, shape=[None, img_flatten], name='x')\n",
    "input_x = tf.reshape(x,[-1,img_size,img_size,1])\n",
    "y = tf.placeholder(tf.float32, shape=[None, num_classes], name='y')\n",
    "y_cls = tf.argmax(y,dimension=1)\n",
    "\n",
    "conv1 = tf.layers.conv2d(inputs=input_x,filters=8,kernel_size=5,padding=\"same\",activation=tf.nn.relu);\n",
    "pool1 = tf.layers.max_pooling2d(inputs=conv1,pool_size=2,strides=2);\n",
    "conv2 = tf.layers.conv2d(inputs=pool1,filters=15,kernel_size=5,padding=\"same\",activation=tf.nn.relu);\n",
    "pool2 = tf.layers.max_pooling2d(inputs=conv2,pool_size=2,strides=2);\n",
    "flat1 = tf.layers.flatten(pool2);\n",
    "fc1 = tf.layers.dense(inputs=flat1,units=10,activation=tf.nn.relu);\n",
    "logits = tf.layers.dense(inputs=fc1,units=num_classes,activation=None);\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=logits);\n",
    "loss = tf.reduce_mean(cross_entropy);\n",
    "\n",
    "# Accuracy\n",
    "softmax = tf.nn.softmax(logits=logits);\n",
    "pred_op = tf.argmax(softmax,dimension=1);\n",
    "acc_op = tf.reduce_mean(tf.cast(tf.equal(pred_op, y_cls), tf.float32));\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.005);\n",
    "train_op = optimizer.minimize(loss);\n",
    "\n",
    "param6 = parameter_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Model 6 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:      0, Training Loss: 0.0368607, Training Accuracy:  98.4%, Test Loss: 0.0766295, Test Accuracy:  97.4%\n",
      "Epoch:      1, Training Loss: 0.0652636, Training Accuracy:  98.4%, Test Loss: 0.0634395, Test Accuracy:  98.0%\n",
      "Epoch:      2, Training Loss: 0.0302847, Training Accuracy:  98.4%, Test Loss: 0.0442813, Test Accuracy:  98.7%\n",
      "Epoch:      3, Training Loss: 0.0959103, Training Accuracy:  95.3%, Test Loss: 0.052783, Test Accuracy:  98.3%\n",
      "Epoch:      4, Training Loss: 0.0188064, Training Accuracy: 100.0%, Test Loss: 0.0441605, Test Accuracy:  98.6%\n"
     ]
    }
   ],
   "source": [
    "train_loss_list6= []\n",
    "train_acc_list6 = []\n",
    "test_loss_list6 = []\n",
    "test_acc_list6 = []\n",
    "\n",
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EPOCH = 5\n",
    "for i in range(EPOCH):\n",
    "    for j in range(int(data.train.num_examples/BATCH_SIZE)):\n",
    "\n",
    "        x_batch, y_true_batch = data.train.next_batch(BATCH_SIZE)\n",
    "        \n",
    "        session.run(train_op, feed_dict={x: x_batch,y: y_true_batch})\n",
    "    train_loss, train_acc = session.run([loss,acc_op],feed_dict={x:x_batch,y:y_true_batch})\n",
    "    test_loss, test_acc = session.run([loss,acc_op],feed_dict={x:data.test.images,y:data.test.labels})\n",
    "    train_loss_list6.append(train_loss)\n",
    "    train_acc_list6.append(train_acc)\n",
    "    test_loss_list6.append(test_loss)\n",
    "    test_acc_list6.append(test_acc)\n",
    "    msg = \"Epoch: {0:>6}, Training Loss: {1:>1.6}, Training Accuracy: {2:>6.1%}, Test Loss: {3:>1.6}, Test Accuracy: {4:>6.1%}\"\n",
    "    print(msg.format(i, train_loss, train_acc, test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 7.1 Model 7 Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'conv2d/kernel:0' shape=(5, 5, 1, 4) dtype=float32_ref>\n",
      "<tf.Variable 'conv2d/bias:0' shape=(4,) dtype=float32_ref>\n",
      "<tf.Variable 'conv2d_1/kernel:0' shape=(5, 5, 4, 15) dtype=float32_ref>\n",
      "<tf.Variable 'conv2d_1/bias:0' shape=(15,) dtype=float32_ref>\n",
      "<tf.Variable 'dense/kernel:0' shape=(735, 10) dtype=float32_ref>\n",
      "<tf.Variable 'dense/bias:0' shape=(10,) dtype=float32_ref>\n",
      "<tf.Variable 'dense_1/kernel:0' shape=(10, 10) dtype=float32_ref>\n",
      "<tf.Variable 'dense_1/bias:0' shape=(10,) dtype=float32_ref>\n",
      "Total Parameter:  9089\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "x = tf.placeholder(tf.float32, shape=[None, img_flatten], name='x')\n",
    "input_x = tf.reshape(x,[-1,img_size,img_size,1])\n",
    "y = tf.placeholder(tf.float32, shape=[None, num_classes], name='y')\n",
    "y_cls = tf.argmax(y,dimension=1)\n",
    "\n",
    "conv1 = tf.layers.conv2d(inputs=input_x,filters=4,kernel_size=5,padding=\"same\",activation=tf.nn.relu);\n",
    "pool1 = tf.layers.max_pooling2d(inputs=conv1,pool_size=2,strides=2);\n",
    "conv2 = tf.layers.conv2d(inputs=pool1,filters=15,kernel_size=5,padding=\"same\",activation=tf.nn.relu);\n",
    "pool2 = tf.layers.max_pooling2d(inputs=conv2,pool_size=2,strides=2);\n",
    "flat1 = tf.layers.flatten(pool2);\n",
    "fc1 = tf.layers.dense(inputs=flat1,units=10,activation=tf.nn.relu);\n",
    "logits = tf.layers.dense(inputs=fc1,units=num_classes,activation=None);\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=logits);\n",
    "loss = tf.reduce_mean(cross_entropy);\n",
    "\n",
    "# Accuracy\n",
    "softmax = tf.nn.softmax(logits=logits);\n",
    "pred_op = tf.argmax(softmax,dimension=1);\n",
    "acc_op = tf.reduce_mean(tf.cast(tf.equal(pred_op, y_cls), tf.float32));\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.005);\n",
    "train_op = optimizer.minimize(loss);\n",
    "\n",
    "param7 = parameter_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Model 7 Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:      0, Training Loss: 0.0709381, Training Accuracy:  96.9%, Test Loss: 0.115695, Test Accuracy:  96.5%\n",
      "Epoch:      1, Training Loss: 0.0889735, Training Accuracy:  96.9%, Test Loss: 0.086189, Test Accuracy:  97.5%\n",
      "Epoch:      2, Training Loss: 0.138116, Training Accuracy:  96.9%, Test Loss: 0.0768443, Test Accuracy:  97.5%\n",
      "Epoch:      3, Training Loss: 0.0181357, Training Accuracy: 100.0%, Test Loss: 0.0646828, Test Accuracy:  98.2%\n",
      "Epoch:      4, Training Loss: 0.0220521, Training Accuracy: 100.0%, Test Loss: 0.0766277, Test Accuracy:  97.7%\n"
     ]
    }
   ],
   "source": [
    "train_loss_list7= []\n",
    "train_acc_list7 = []\n",
    "test_loss_list7 = []\n",
    "test_acc_list7 = []\n",
    "\n",
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EPOCH = 5\n",
    "for i in range(EPOCH):\n",
    "    for j in range(int(data.train.num_examples/BATCH_SIZE)):\n",
    "\n",
    "        x_batch, y_true_batch = data.train.next_batch(BATCH_SIZE)\n",
    "        \n",
    "        session.run(train_op, feed_dict={x: x_batch,y: y_true_batch})\n",
    "    train_loss, train_acc = session.run([loss,acc_op],feed_dict={x:x_batch,y:y_true_batch})\n",
    "    test_loss, test_acc = session.run([loss,acc_op],feed_dict={x:data.test.images,y:data.test.labels})\n",
    "    train_loss_list7.append(train_loss)\n",
    "    train_acc_list7.append(train_acc)\n",
    "    test_loss_list7.append(test_loss)\n",
    "    test_acc_list7.append(test_acc)\n",
    "    msg = \"Epoch: {0:>6}, Training Loss: {1:>1.6}, Training Accuracy: {2:>6.1%}, Test Loss: {3:>1.6}, Test Accuracy: {4:>6.1%}\"\n",
    "    print(msg.format(i, train_loss, train_acc, test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 8.1 Model 8 Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'conv2d/kernel:0' shape=(5, 5, 1, 4) dtype=float32_ref>\n",
      "<tf.Variable 'conv2d/bias:0' shape=(4,) dtype=float32_ref>\n",
      "<tf.Variable 'conv2d_1/kernel:0' shape=(5, 5, 4, 10) dtype=float32_ref>\n",
      "<tf.Variable 'conv2d_1/bias:0' shape=(10,) dtype=float32_ref>\n",
      "<tf.Variable 'dense/kernel:0' shape=(490, 10) dtype=float32_ref>\n",
      "<tf.Variable 'dense/bias:0' shape=(10,) dtype=float32_ref>\n",
      "<tf.Variable 'dense_1/kernel:0' shape=(10, 10) dtype=float32_ref>\n",
      "<tf.Variable 'dense_1/bias:0' shape=(10,) dtype=float32_ref>\n",
      "Total Parameter:  6134\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "x = tf.placeholder(tf.float32, shape=[None, img_flatten], name='x')\n",
    "input_x = tf.reshape(x,[-1,img_size,img_size,1])\n",
    "y = tf.placeholder(tf.float32, shape=[None, num_classes], name='y')\n",
    "y_cls = tf.argmax(y,dimension=1)\n",
    "\n",
    "conv1 = tf.layers.conv2d(inputs=input_x,filters=4,kernel_size=5,padding=\"same\",activation=tf.nn.relu);\n",
    "pool1 = tf.layers.max_pooling2d(inputs=conv1,pool_size=2,strides=2);\n",
    "conv2 = tf.layers.conv2d(inputs=pool1,filters=10,kernel_size=5,padding=\"same\",activation=tf.nn.relu);\n",
    "pool2 = tf.layers.max_pooling2d(inputs=conv2,pool_size=2,strides=2);\n",
    "flat1 = tf.layers.flatten(pool2);\n",
    "fc1 = tf.layers.dense(inputs=flat1,units=10,activation=tf.nn.relu);\n",
    "logits = tf.layers.dense(inputs=fc1,units=num_classes,activation=None);\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=logits);\n",
    "loss = tf.reduce_mean(cross_entropy);\n",
    "\n",
    "# Accuracy\n",
    "softmax = tf.nn.softmax(logits=logits);\n",
    "pred_op = tf.argmax(softmax,dimension=1);\n",
    "acc_op = tf.reduce_mean(tf.cast(tf.equal(pred_op, y_cls), tf.float32));\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.005);\n",
    "train_op = optimizer.minimize(loss);\n",
    "\n",
    "param8 = parameter_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Model 8 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:      0, Training Loss: 0.0686198, Training Accuracy:  96.9%, Test Loss: 0.100408, Test Accuracy:  96.7%\n",
      "Epoch:      1, Training Loss: 0.211625, Training Accuracy:  93.8%, Test Loss: 0.0984913, Test Accuracy:  96.9%\n",
      "Epoch:      2, Training Loss: 0.111864, Training Accuracy:  95.3%, Test Loss: 0.0797624, Test Accuracy:  97.3%\n",
      "Epoch:      3, Training Loss: 0.0116949, Training Accuracy: 100.0%, Test Loss: 0.0554739, Test Accuracy:  98.1%\n",
      "Epoch:      4, Training Loss: 0.00453868, Training Accuracy: 100.0%, Test Loss: 0.0543268, Test Accuracy:  98.3%\n"
     ]
    }
   ],
   "source": [
    "train_loss_list8= []\n",
    "train_acc_list8 = []\n",
    "test_loss_list8 = []\n",
    "test_acc_list8 = []\n",
    "\n",
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EPOCH = 5\n",
    "for i in range(EPOCH):\n",
    "    for j in range(int(data.train.num_examples/BATCH_SIZE)):\n",
    "\n",
    "        x_batch, y_true_batch = data.train.next_batch(BATCH_SIZE)\n",
    "        \n",
    "        session.run(train_op, feed_dict={x: x_batch,y: y_true_batch})\n",
    "    train_loss, train_acc = session.run([loss,acc_op],feed_dict={x:x_batch,y:y_true_batch})\n",
    "    test_loss, test_acc = session.run([loss,acc_op],feed_dict={x:data.test.images,y:data.test.labels})\n",
    "    train_loss_list8.append(train_loss)\n",
    "    train_acc_list8.append(train_acc)\n",
    "    test_loss_list8.append(test_loss)\n",
    "    test_acc_list8.append(test_acc)\n",
    "    msg = \"Epoch: {0:>6}, Training Loss: {1:>1.6}, Training Accuracy: {2:>6.1%}, Test Loss: {3:>1.6}, Test Accuracy: {4:>6.1%}\"\n",
    "    print(msg.format(i, train_loss, train_acc, test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 9.1 Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'conv2d/kernel:0' shape=(5, 5, 1, 5) dtype=float32_ref>\n",
      "<tf.Variable 'conv2d/bias:0' shape=(5,) dtype=float32_ref>\n",
      "<tf.Variable 'conv2d_1/kernel:0' shape=(5, 5, 5, 5) dtype=float32_ref>\n",
      "<tf.Variable 'conv2d_1/bias:0' shape=(5,) dtype=float32_ref>\n",
      "<tf.Variable 'dense/kernel:0' shape=(245, 10) dtype=float32_ref>\n",
      "<tf.Variable 'dense/bias:0' shape=(10,) dtype=float32_ref>\n",
      "<tf.Variable 'dense_1/kernel:0' shape=(10, 10) dtype=float32_ref>\n",
      "<tf.Variable 'dense_1/bias:0' shape=(10,) dtype=float32_ref>\n",
      "Total Parameter:  3330\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "x = tf.placeholder(tf.float32, shape=[None, img_flatten], name='x')\n",
    "input_x = tf.reshape(x,[-1,img_size,img_size,1])\n",
    "y = tf.placeholder(tf.float32, shape=[None, num_classes], name='y')\n",
    "y_cls = tf.argmax(y,dimension=1)\n",
    "\n",
    "conv1 = tf.layers.conv2d(inputs=input_x,filters=5,kernel_size=5,padding=\"same\",activation=tf.nn.relu);\n",
    "pool1 = tf.layers.max_pooling2d(inputs=conv1,pool_size=2,strides=2);\n",
    "conv2 = tf.layers.conv2d(inputs=pool1,filters=5,kernel_size=5,padding=\"same\",activation=tf.nn.relu);\n",
    "pool2 = tf.layers.max_pooling2d(inputs=conv2,pool_size=2,strides=2);\n",
    "flat1 = tf.layers.flatten(pool2);\n",
    "fc1 = tf.layers.dense(inputs=flat1,units=10,activation=tf.nn.relu);\n",
    "logits = tf.layers.dense(inputs=fc1,units=num_classes,activation=None);\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=logits);\n",
    "loss = tf.reduce_mean(cross_entropy);\n",
    "\n",
    "# Accuracy\n",
    "softmax = tf.nn.softmax(logits=logits);\n",
    "pred_op = tf.argmax(softmax,dimension=1);\n",
    "acc_op = tf.reduce_mean(tf.cast(tf.equal(pred_op, y_cls), tf.float32));\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.005);\n",
    "train_op = optimizer.minimize(loss);\n",
    "\n",
    "param9 = parameter_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2 Model 9 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:      0, Training Loss: 0.204651, Training Accuracy:  92.2%, Test Loss: 0.089405, Test Accuracy:  97.0%\n",
      "Epoch:      1, Training Loss: 0.00727753, Training Accuracy: 100.0%, Test Loss: 0.0829676, Test Accuracy:  97.5%\n",
      "Epoch:      2, Training Loss: 0.0067563, Training Accuracy: 100.0%, Test Loss: 0.0656416, Test Accuracy:  98.0%\n",
      "Epoch:      3, Training Loss: 0.00718814, Training Accuracy: 100.0%, Test Loss: 0.0629184, Test Accuracy:  98.1%\n",
      "Epoch:      4, Training Loss: 0.00705767, Training Accuracy: 100.0%, Test Loss: 0.053069, Test Accuracy:  98.4%\n"
     ]
    }
   ],
   "source": [
    "train_loss_list9= []\n",
    "train_acc_list9 = []\n",
    "test_loss_list9 = []\n",
    "test_acc_list9 = []\n",
    "\n",
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EPOCH = 5\n",
    "for i in range(EPOCH):\n",
    "    for j in range(int(data.train.num_examples/BATCH_SIZE)):\n",
    "\n",
    "        x_batch, y_true_batch = data.train.next_batch(BATCH_SIZE)\n",
    "        \n",
    "        session.run(train_op, feed_dict={x: x_batch,y: y_true_batch})\n",
    "    train_loss, train_acc = session.run([loss,acc_op],feed_dict={x:x_batch,y:y_true_batch})\n",
    "    test_loss, test_acc = session.run([loss,acc_op],feed_dict={x:data.test.images,y:data.test.labels})\n",
    "    train_loss_list9.append(train_loss)\n",
    "    train_acc_list9.append(train_acc)\n",
    "    test_loss_list9.append(test_loss)\n",
    "    test_acc_list9.append(test_acc)\n",
    "    msg = \"Epoch: {0:>6}, Training Loss: {1:>1.6}, Training Accuracy: {2:>6.1%}, Test Loss: {3:>1.6}, Test Accuracy: {4:>6.1%}\"\n",
    "    print(msg.format(i, train_loss, train_acc, test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 10.1 Model 10 Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'conv2d/kernel:0' shape=(5, 5, 1, 1) dtype=float32_ref>\n",
      "<tf.Variable 'conv2d/bias:0' shape=(1,) dtype=float32_ref>\n",
      "<tf.Variable 'conv2d_1/kernel:0' shape=(5, 5, 1, 1) dtype=float32_ref>\n",
      "<tf.Variable 'conv2d_1/bias:0' shape=(1,) dtype=float32_ref>\n",
      "<tf.Variable 'dense/kernel:0' shape=(49, 10) dtype=float32_ref>\n",
      "<tf.Variable 'dense/bias:0' shape=(10,) dtype=float32_ref>\n",
      "Total Parameter:  552\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "x = tf.placeholder(tf.float32, shape=[None, img_flatten], name='x')\n",
    "input_x = tf.reshape(x,[-1,img_size,img_size,1])\n",
    "y = tf.placeholder(tf.float32, shape=[None, num_classes], name='y')\n",
    "y_cls = tf.argmax(y,dimension=1)\n",
    "\n",
    "conv1 = tf.layers.conv2d(inputs=input_x,filters=1,kernel_size=5,padding=\"same\",activation=tf.nn.relu);\n",
    "pool1 = tf.layers.max_pooling2d(inputs=conv1,pool_size=2,strides=2);\n",
    "conv2 = tf.layers.conv2d(inputs=pool1,filters=1,kernel_size=5,padding=\"same\",activation=tf.nn.relu);\n",
    "pool2 = tf.layers.max_pooling2d(inputs=conv2,pool_size=2,strides=2);\n",
    "flat1 = tf.layers.flatten(pool2);\n",
    "logits = tf.layers.dense(inputs=flat1,units=num_classes,activation=None);\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=logits);\n",
    "loss = tf.reduce_mean(cross_entropy);\n",
    "\n",
    "# Accuracy\n",
    "softmax = tf.nn.softmax(logits=logits);\n",
    "pred_op = tf.argmax(softmax,dimension=1);\n",
    "acc_op = tf.reduce_mean(tf.cast(tf.equal(pred_op, y_cls), tf.float32));\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.005);\n",
    "train_op = optimizer.minimize(loss);\n",
    "\n",
    "param10 = parameter_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2 Model 10 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_list10= []\n",
    "train_acc_list10 = []\n",
    "test_loss_list10 = []\n",
    "test_acc_list10 = []\n",
    "\n",
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EPOCH = 5\n",
    "for i in range(EPOCH):\n",
    "    for j in range(int(data.train.num_examples/BATCH_SIZE)):\n",
    "\n",
    "        x_batch, y_true_batch = data.train.next_batch(BATCH_SIZE)\n",
    "        \n",
    "        session.run(train_op, feed_dict={x: x_batch,y: y_true_batch})\n",
    "    train_loss, train_acc = session.run([loss,acc_op],feed_dict={x:x_batch,y:y_true_batch})\n",
    "    test_loss, test_acc = session.run([loss,acc_op],feed_dict={x:data.test.images,y:data.test.labels})\n",
    "    train_loss_list10.append(train_loss)\n",
    "    train_acc_list10.append(train_acc)\n",
    "    test_loss_list10.append(test_loss)\n",
    "    test_acc_list10.append(test_acc)\n",
    "    msg = \"Epoch: {0:>6}, Training Loss: {1:>1.6}, Training Accuracy: {2:>6.1%}, Test Loss: {3:>1.6}, Test Accuracy: {4:>6.1%}\"\n",
    "    print(msg.format(i, train_loss, train_acc, test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_HW1",
   "language": "python",
   "name": "dl_hw1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
